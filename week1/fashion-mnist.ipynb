{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Dense, MaxPooling2D, \\\n    Flatten, Dropout, GlobalAveragePooling2D, Layer, Input, add, ReLU, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nfrom tensorflow.image import random_flip_left_right, random_flip_up_down, random_brightness","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds, ds_info = tfds.load('fashion_mnist', with_info=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Within each of these, the iterator produces a single dict\n# Within the dict is 'image' and 'label' keys\nds_train = ds['train']\nds_test = ds['test']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nCode for making Tensors have slice-able assignment from StackOverflow user: Tensorflow Support\nhttps://stackoverflow.com/questions/54086836/how-to-fix-sliced-assignment-is-only-supported-for-variables-for-tensors\n\nThis custom class and methods are needed for the application of random erasing augmentation\n\"\"\"\n\ndef replace_slice(input_, replacement, begin, size=None):\n    inp_shape = tf.shape(input_)\n    if size is None:\n        size = tf.shape(replacement)\n    else:\n        replacement = tf.broadcast_to(replacement, size)\n    padding = tf.stack([begin, inp_shape - (begin + size)], axis=1)\n    replacement_pad = tf.pad(replacement, padding)\n    mask = tf.pad(tf.ones_like(replacement, dtype=tf.bool), padding)\n    return tf.where(mask, replacement_pad, input_)\n\ndef replace_slice_in(tensor):\n    return _SliceReplacer(tensor)\n\nclass _SliceReplacer:\n    def __init__(self, tensor):\n        self._tensor = tensor\n    def __getitem__(self, slices):\n        return _SliceReplacer._Inner(self._tensor, slices)\n    def with_value(self, replacement):  # Just for convenience in case you skip the indexing\n        return _SliceReplacer._Inner(self._tensor, (...,)).with_value(replacement)\n    class _Inner:\n        def __init__(self, tensor, slices):\n            self._tensor = tensor\n            self._slices = slices\n        def with_value(self, replacement):\n            begin, size = _make_slices_begin_size(self._tensor, self._slices)\n            return replace_slice(self._tensor, replacement, begin, size)\n\n# This computes begin and size values for a set of slices\ndef _make_slices_begin_size(input_, slices):\n    if not isinstance(slices, (tuple, list)):\n        slices = (slices,)\n    inp_rank = tf.rank(input_)\n    inp_shape = tf.shape(input_)\n    # Did we see a ellipsis already?\n    before_ellipsis = True\n    # Sliced dimensions\n    dim_idx = []\n    # Slice start points\n    begins = []\n    # Slice sizes\n    sizes = []\n    for i, s in enumerate(slices):\n        if s is Ellipsis:\n            if not before_ellipsis:\n                raise ValueError('Cannot use more than one ellipsis in slice spec.')\n            before_ellipsis = False\n            continue\n        if isinstance(s, slice):\n            start = s.start\n            stop = s.stop\n            if s.step is not None:\n                raise ValueError('Step value not supported.')\n        else:  # Assumed to be a single integer value\n            start = s\n            stop = s + 1\n        # Dimension this slice refers to\n        i_dim = i if before_ellipsis else inp_rank - (len(slices) - i)\n        dim_size = inp_shape[i_dim]\n        # Default slice values\n        start = start if start is not None else 0\n        stop = stop if stop is not None else dim_size\n        # Fix negative indices\n        start = tf.cond(tf.convert_to_tensor(start >= 0), lambda: start, lambda: start + dim_size)\n        stop = tf.cond(tf.convert_to_tensor(stop >= 0), lambda: stop, lambda: stop + dim_size)\n        dim_idx.append([i_dim])\n        begins.append(start)\n        sizes.append(stop - start)\n    # For empty slice specs like [...]\n    if not dim_idx:\n        return tf.zeros_like(inp_shape), inp_shape\n    # Make full begin and size array (including omitted dimensions)\n    begin_full = tf.scatter_nd(dim_idx, begins, [inp_rank])\n    size_mask = tf.scatter_nd(dim_idx, tf.ones_like(sizes, dtype=tf.bool), [inp_rank])\n    size_full = tf.where(size_mask,\n                          tf.scatter_nd(dim_idx, sizes, [inp_rank]),\n                          inp_shape)\n    return begin_full, size_full\n\ndef random_erasing(img, probability = 0.08, sl = 0.02, sh = 0.4, r1 = 0.3):\n    '''\n    img is a 3-D variable (ex: tf.Variable(image, validate_shape=False) ) and  HWC order\n    '''\n    # HWC order\n    height = 28\n    width = 28\n    channel = 1\n    area = tf.cast(784, tf.float32)\n\n    erase_area_low_bound = tf.cast(tf.round(tf.sqrt(sl * area * r1)), tf.int32)\n    erase_area_up_bound = tf.cast(tf.round(tf.sqrt((sh * area) / r1)), tf.int32)\n    h_upper_bound = tf.minimum(erase_area_up_bound, height)\n    w_upper_bound = tf.minimum(erase_area_up_bound, width)\n\n    h = tf.random.uniform([], erase_area_low_bound, h_upper_bound, tf.int32)\n    w = tf.random.uniform([], erase_area_low_bound, w_upper_bound, tf.int32)\n\n    x1 = tf.random.uniform([], 0, height+1 - h, tf.int32)\n    y1 = tf.random.uniform([], 0, width+1 - w, tf.int32)\n\n    erase_area = tf.cast(tf.random.uniform([h, w, channel], 0, 1, tf.int32), tf.float32)\n    erasing_img = replace_slice_in(img)[x1:x1+h, y1:y1+w, :].with_value(erase_area)\n#     erasing_img = img[x1:x1+h, y1:y1+w, :].assign(erase_area)\n\n    return tf.cond(tf.random.uniform([], 0, 1) > probability, lambda: img, lambda: erasing_img)\n\ndef augment_train(data):\n    image = data['image']\n    label = data['label']\n    image = tf.cast(image, tf.float32)\n    image /= 255.0\n    \n    image = random_flip_left_right(image)\n    image = random_flip_up_down(image)\n    image = random_brightness(image, 0.3)\n    image = random_erasing(image)\n    \n    return image, label\n\ndef augment_test(data):\n    image = data['image']\n    label = data['label']\n    image = tf.cast(image, tf.float32)\n    image /= 255.0\n    \n    image = random_flip_left_right(image)\n    image = random_flip_up_down(image)\n    image = random_brightness(image, 0.3)\n    \n    return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 1024\n\nds_train = (\n    ds_train\n    .map(augment_train, num_parallel_calls=AUTO)\n    .shuffle(10000)\n    .batch(batch_size)\n    .prefetch(AUTO)\n)\n\nds_test = (\n    ds_test\n    .map(augment_train, num_parallel_calls=AUTO)\n    .batch(batch_size)\n    .prefetch(AUTO)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ResNet Architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResidualBlock(Layer):\n    \"\"\"\n    Introduced by He et al. (2015): https://arxiv.org/pdf/1512.03385.pdf\n    Just as in the original implementation, we apply batch normalization BEFORE the layer's activation (hence activation=None).\n    In addition, this residual block performs the identity mapping in the skip connection, just as in the smaller (18, 34)\n        ResNets from the original paper. This is explained in 1st paragraph of \"Residual Network.\" subsection on page 5.\n    \n    Attributes:\n        filters (int): the number of filters in the convolutional layers in this residual block\n        dim_increase (bool): indicates whether this block has an increase in filter dimensions from the residual block before it.\n            in the original paper, the authors propose two options: (a) identiy mapping with zero-padding for extra space or \n            (b) shortcut connection with Network-in-Network (1x1 convolution) connection. This is explained in \"Residual Network.\"\n            subsection on page 4. We choose to use (b). Both options use a stride of 2 in the first convolution.\n    \"\"\"\n    \n    \n    def __init__(self, filters, dim_increase):\n        super(ResidualBlock, self).__init__()\n        \n        self.filters = filters\n        self.dim_increase = dim_increase\n\n            \n        if filters != 64 and dim_increase:\n            self.conv1 = Conv2D(kernel_size=(3, 3), filters=filters, activation=None,\n                               padding='same', strides=2) \n            self.conv2 = Conv2D(kernel_size=(3, 3), filters=filters,\n                               activation=None, padding='same')\n            \n        else:\n            self.conv1 = Conv2D(kernel_size=(3, 3), filters=filters,\n                                activation=None, padding='same')\n            self.conv2 = Conv2D(kernel_size=(3, 3), filters=filters,\n                                activation=None, padding='same')\n        \n        self.bn1 = BatchNormalization()\n        self.bn2 = BatchNormalization()\n        self.bn_resid = BatchNormalization()\n        \n        if dim_increase:\n            self.residual_connection = Conv2D(kernel_size=(1, 1), filters=filters, strides=2, activation=None)\n        else:\n            self.residual_connection = lambda x: x\n            \n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'filters': self.filters,\n            'dim_increase': self.dim_increase\n        })\n        \n        return config\n            \n    def call(self, x):\n        if self.dim_increase:\n            resid = self.residual_connection(x)\n            resid = self.bn_resid(resid)\n            resid = tf.nn.relu(resid)\n        else:\n            resid = self.residual_connection(x)\n            \n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = tf.nn.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = tf.nn.relu(x)\n        output = tf.nn.relu(add([resid, x]))\n        return output\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_SHAPE = (28, 28, 1)\n\nresnet18 = tf.keras.Sequential([\n    Input(shape=INPUT_SHAPE),\n    Conv2D(kernel_size=(7, 7), filters=64, strides=2, activation=None, padding='same'),\n    BatchNormalization(),\n    ReLU(),\n    MaxPooling2D(pool_size=(3, 3), strides=2),\n    ResidualBlock(filters=64, dim_increase=False),\n    ResidualBlock(filters=64, dim_increase=False),\n    ResidualBlock(filters=128, dim_increase=True),\n    ResidualBlock(filters=128, dim_increase=False),\n    ResidualBlock(filters=256, dim_increase=True),\n    ResidualBlock(filters=256, dim_increase=False),\n    Dropout(0.10),\n    ResidualBlock(filters=512, dim_increase=True),\n    Dropout(0.10),\n    ResidualBlock(filters=512, dim_increase=False),\n    Dropout(0.10),\n    GlobalAveragePooling2D(),\n    Dense(10, activation='softmax'),\n    Dropout(0.10)\n])\n\nresnet18.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n                 optimizer=tf.keras.optimizers.Adam(),\n                 metrics=tf.keras.metrics.SparseCategoricalAccuracy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet18.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [\n    tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy', patience=150),\n    \n]\n\ntrain_hist = resnet18.fit(\n    ds_train, \n    epochs=500,\n    validation_data=ds_test,\n    callbacks=callbacks\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_hist.history['sparse_categorical_accuracy'])\nplt.plot(train_hist.history['val_sparse_categorical_accuracy'])\nplt.legend(['Train', 'Test'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet18.save('resnet18.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Looking into accuracy"},{"metadata":{},"cell_type":"markdown","source":"##### Loding the model (if needed)"},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_SHAPE = (28, 28, 1)\n\nresnet18 = tf.keras.Sequential([\n    Input(shape=INPUT_SHAPE),\n    Conv2D(kernel_size=(7, 7), filters=64, strides=2, activation=None, padding='same'),\n    BatchNormalization(),\n    ReLU(),\n    MaxPooling2D(pool_size=(3, 3), strides=2),\n    ResidualBlock(filters=64, dim_increase=False),\n    ResidualBlock(filters=64, dim_increase=False),\n    ResidualBlock(filters=128, dim_increase=True),\n    ResidualBlock(filters=128, dim_increase=False),\n    ResidualBlock(filters=256, dim_increase=True),\n    ResidualBlock(filters=256, dim_increase=False),\n    Dropout(0.10),\n    ResidualBlock(filters=512, dim_increase=True),\n    Dropout(0.10),\n    ResidualBlock(filters=512, dim_increase=False),\n    Dropout(0.10),\n    GlobalAveragePooling2D(),\n    Dense(10, activation='softmax'),\n    Dropout(0.10)\n])\n\n\nresnet18.load_weights('./resnet18.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reloading the models without the probabilistic augmentations...\nds_train = ds['train']\nds_test = ds['test']\n\nbatch_size = 1024\n\n\ndef augment_inference(data):\n    image = data['image']\n    label = data['label']\n    image = tf.cast(image, tf.float32)\n    image /= 255.0\n    \n    return image, label\n\nds_train = (\n    ds_train\n    .map(augment_inference, num_parallel_calls=AUTO)\n    .batch(batch_size)\n    .prefetch(AUTO)\n)\n\nds_test = (\n    ds_test\n    .map(augment_inference, num_parallel_calls=AUTO)\n    .batch(batch_size)\n    .prefetch(AUTO)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nlabels = []\nfor xdata, label in ds_train:\n    p = resnet18(xdata)\n    preds.append(p.numpy())\n    labels.append(label.numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unrolled_preds = []\nfor p in preds:\n    for j in p:\n        unrolled_preds.append(np.argmax(j))\n        \nunrolled_labels = []\nfor l in labels:\n    for j in l:\n        unrolled_labels.append(j)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = np.sum(np.array(unrolled_preds) == np.array(unrolled_labels)) / len(unrolled_preds)\nprint(f'Training set accuracy: {acc}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nlabels = []\nfor xdata, label in ds_test:\n    p = resnet18(xdata)\n    preds.append(p.numpy())\n    labels.append(label.numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unrolled_preds = []\nfor p in preds:\n    for j in p:\n        unrolled_preds.append(np.argmax(j))\n        \nunrolled_labels = []\nfor l in labels:\n    for j in l:\n        unrolled_labels.append(j)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = np.sum(np.array(unrolled_preds) == np.array(unrolled_labels)) / len(unrolled_preds)\nprint(f'Test set accuracy: {acc}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}